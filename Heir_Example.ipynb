{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchhd\n",
    "import HierGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for calculating performance metrics\n",
    "\n",
    "def perf_measure(y_actual, y_hat):\n",
    "    '''\n",
    "    Compute precision, recall, and F1 score between predicted and actual labels.\n",
    "    '''\n",
    "    # Generate a classification report with precision, recall, and F1 score\n",
    "    # for each class. Store the report as a dictionary.\n",
    "    report = classification_report(y_actual,y_hat, output_dict=True)\n",
    "    precision = report['macro avg']['precision']\n",
    "    recall = report['macro avg']['recall']\n",
    "    f1 = report['macro avg']['f1-score']\n",
    "\n",
    "    # Return the precision, recall, and F1 score as a tuple\n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500, 64, 10)\n",
      "(1500,)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "def generate_random_data(shape):\n",
    "    return np.random.random(shape)\n",
    "\n",
    "def generate_sinusoidal_data(shape):\n",
    "    time = np.linspace(0, 2 * np.pi, shape[0]*shape[1]*shape[2])\n",
    "    return np.sin(time).reshape(shape)\n",
    "\n",
    "def generate_consecutive_data(shape):\n",
    "    total_elements = np.prod(shape)\n",
    "    return np.arange(total_elements).reshape(shape)\n",
    "\n",
    "# Parameters\n",
    "num_samples = 500\n",
    "num_time_step = 10\n",
    "shape = (num_samples, 64, num_time_step)\n",
    "\n",
    "\n",
    "# Generate data using the three functions\n",
    "data_random = generate_random_data(shape)\n",
    "data_sinusoidal = generate_sinusoidal_data(shape)\n",
    "data_consecutive = generate_consecutive_data(shape)\n",
    "\n",
    "# Create labels\n",
    "labels_random = np.zeros(num_samples, dtype=int)\n",
    "labels_sinusoidal = np.ones(num_samples, dtype=int)\n",
    "labels_consecutive = np.full(num_samples, 2, dtype=int)\n",
    "\n",
    "# Combine data and labels\n",
    "data = np.concatenate((data_random, data_sinusoidal, data_consecutive), axis=0)\n",
    "labels = np.concatenate((labels_random, labels_sinusoidal, labels_consecutive), axis=0)\n",
    "\n",
    "print(data.shape)\n",
    "print(labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hp/q8jzttm906905kc7xnl0ynx40000gn/T/ipykernel_63200/3045121236.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  parameter_adj_mat = np.array([[0, 1, 2, 3, 4, 5], #which channel corresponds to which parameter\n"
     ]
    }
   ],
   "source": [
    "channel_mat = np.array([6,6,6,5,5,6,3,5,6,4,3,3,6]) #num of channels per parameter\n",
    "parameter_adj_mat = np.array([[0, 1, 2, 3, 4, 5], #which channel corresponds to which parameter\n",
    "                         [6, 7, 8, 9, 10, 11],\n",
    "                         [12, 13, 14, 15, 16, 17],\n",
    "                         [18, 19, 20, 21, 22],\n",
    "                         [23, 24, 25, 26, 27],\n",
    "                         [28, 29, 30, 31, 32, 33],\n",
    "                         [34, 35, 36],\n",
    "                         [37, 38, 39, 40, 41],\n",
    "                         [42, 43, 44, 45, 46, 47],\n",
    "                         [48, 49, 50, 51],\n",
    "                         [52, 53, 54],\n",
    "                         [55, 56, 57],\n",
    "                         [58, 59, 60, 61, 62, 63]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = np.unique(labels).size\n",
    "parameters={'dim': 1000, 'alpha': 20.0, 'lr': .5, 'epoch': 100, 'T': 0.1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data, labels, stratify=labels, test_size = .2) #stratify=yy\n",
    "\n",
    "y_test = torch.from_numpy(y_test).long()\n",
    "\n",
    "test = HierGraph.hiergraph(num_classes,channel_mat,parameter_adj_mat,num_time_step,embedding_type='density',dim=parameters['dim'],VSA='MAP')\n",
    "test = test.fit(x_train,y_train,lr=parameters['lr'],alpha=parameters['alpha'],epochs=parameters['epoch'],T=parameters['T'],iter=1)\n",
    "\n",
    "sim_parameter = torchhd.cos(test.parameter_hv,test.class_hv).numpy()\n",
    "sim_channel = torchhd.cos(test.channel_hv,test.class_hv).numpy()\n",
    "sim_channel_para = torchhd.cos(test.channel_hv,test.parameter_hv).numpy()\n",
    "\n",
    "y_hat = test(x_test)\n",
    "acc_test_all = np.array((y_test == y_hat).float().mean())\n",
    "cur_precision_all, cur_recall_all, cur_f1_all = perf_measure(y_test,y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.88\n"
     ]
    }
   ],
   "source": [
    "print(acc_test_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.70      0.80       100\n",
      "           1       0.76      0.94      0.84       100\n",
      "           2       0.98      1.00      0.99       100\n",
      "\n",
      "    accuracy                           0.88       300\n",
      "   macro avg       0.89      0.88      0.88       300\n",
      "weighted avg       0.89      0.88      0.88       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
